Mean Loss from Epoch 1: 0.41942070891857147
Mean Loss from Epoch 2: 0.21270755730668703
Mean Loss from Epoch 3: 0.16270859456111988
Mean Loss from Epoch 4: 0.13155072764754294
Mean Loss from Epoch 5: 0.11061497289513549
Mean Loss from Epoch 6: 0.09437433366974195
Mean Loss from Epoch 7: 0.08198303720541299
Mean Loss from Epoch 8: 0.07220526723240812
Mean Loss from Epoch 9: 0.06332741599076738
Mean Loss from Epoch 10: 0.05652659239117056
Mean Loss from Epoch 11: 0.05090956721287221
Mean Loss from Epoch 12: 0.045950685619562864
Mean Loss from Epoch 13: 0.04120308045068135
Mean Loss from Epoch 14: 0.03787008545504262
Mean Loss from Epoch 15: 0.03392858896655962
Mean Loss from Epoch 16: 0.030826770547808458
Mean Loss from Epoch 17: 0.027971694055603197
Mean Loss from Epoch 18: 0.024928056378297817
Mean Loss from Epoch 19: 0.02280695091364905
Mean Loss from Epoch 20: 0.020908176772187776
Mean Loss from Epoch 21: 0.019315483528461
Mean Loss from Epoch 22: 0.016980832700586566
Mean Loss from Epoch 23: 0.015550696821681535
Mean Loss from Epoch 24: 0.013997259946757306
Mean Loss from Epoch 25: 0.012566650879109511
Mean Loss from Epoch 26: 0.011884009119301724
Mean Loss from Epoch 27: 0.010564061185643852
Mean Loss from Epoch 28: 0.009072041443479248
Mean Loss from Epoch 1: 0.5026848212480545
Mean Loss from Epoch 2: 0.2534468467652798
Mean Loss from Epoch 3: 0.20550571448504926
Mean Loss from Epoch 4: 0.17261420870820682
Mean Loss from Epoch 5: 0.14878096608842412
Mean Loss from Epoch 6: 0.13105755257358154
Mean Loss from Epoch 7: 0.11826417640410364
Mean Loss from Epoch 8: 0.10693480039462447
Mean Loss from Epoch 9: 0.0987565405819565
Mean Loss from Epoch 10: 0.0898104064291343
Mean Loss from Epoch 11: 0.08336343229773144
Mean Loss from Epoch 12: 0.0785051047038287
Mean Loss from Epoch 13: 0.07336552256122232
Mean Loss from Epoch 14: 0.0701287252281482
Mean Loss from Epoch 15: 0.06463284285397579
Mean Loss from Epoch 16: 0.061585673629834005
Mean Loss from Epoch 17: 0.05774603180143361
Mean Loss from Epoch 18: 0.05443703356534243
Mean Loss from Epoch 19: 0.05146921130130067
Mean Loss from Epoch 20: 0.048384367924478526
Mean Loss from Epoch 21: 0.046352844220461945
Mean Loss from Epoch 22: 0.04294813745515421
Mean Loss from Epoch 23: 0.041163186298512545
Mean Loss from Epoch 24: 0.038541831635070654
Mean Loss from Epoch 25: 0.03650859962958687
Mean Loss from Epoch 26: 0.034274239830020814
Mean Loss from Epoch 27: 0.032943074638443065
Mean Loss from Epoch 28: 0.030568426952146305
Mean Loss from Epoch 29: 0.02999258454168448
Mean Loss from Epoch 30: 0.027419961044479472
Mean Loss from Epoch 31: 0.026717010410797472
Mean Loss from Epoch 32: 0.024599915137696857
Mean Loss from Epoch 33: 0.023361592339219837
Mean Loss from Epoch 34: 0.021967708955406368
Mean Loss from Epoch 35: 0.02099698101259031
Mean Loss from Epoch 36: 0.019930407654463002
Mean Loss from Epoch 37: 0.018217986786448453
Mean Loss from Epoch 38: 0.017756828930060146
Mean Loss from Epoch 39: 0.01672616122874509
Mean Loss from Epoch 40: 0.015798647201021473
Mean Loss from Epoch 41: 0.015110763818588262
Mean Loss from Epoch 42: 0.014408984246000182
Mean Loss from Epoch 43: 0.013794927265754328
Mean Loss from Epoch 44: 0.012855840784826674
Mean Loss from Epoch 45: 0.012363220259651038
Mean Loss from Epoch 46: 0.012018154883770815
Mean Loss from Epoch 47: 0.01151837830979639
Mean Loss from Epoch 48: 0.01076454396215122
Mean Loss from Epoch 49: 0.011088712582541242
Mean Loss from Epoch 50: 0.009484927981256623
Test Loss (F1): 0.0996028831236378
Test Loss (F2): 0.16682597068138247
Accuracy (F1): 0.975
Accuracy (F2): 0.9688
F1 Summary:
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
F1                                       --                        --
├─LinearLayer: 1-1                       [32, 64]                  50,240
├─LinearLayer: 1-2                       [32, 10]                  650
==========================================================================================
Total params: 50,890
Trainable params: 50,890
Non-trainable params: 0
Total mult-adds (M): 1.63
==========================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 0.02
Params size (MB): 0.20
Estimated Total Size (MB): 0.32
==========================================================================================
F2 Summary:
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
F2                                       --                        --
├─LinearLayer: 1-1                       [32, 32]                  25,120
├─LinearLayer: 1-2                       [32, 32]                  1,056
├─LinearLayer: 1-3                       [32, 10]                  330
==========================================================================================
Total params: 26,506
Trainable params: 26,506
Non-trainable params: 0
Total mult-adds (M): 0.85
==========================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 0.02
Params size (MB): 0.11
Estimated Total Size (MB): 0.23
==========================================================================================
