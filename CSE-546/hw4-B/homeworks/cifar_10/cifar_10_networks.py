# -*- coding: utf-8 -*-
"""cifar_10_networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJ0UCw48pyIAt3BrDAKaJwbeXEmAWFq3
"""

import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset
from torch.optim import Adam
import torchvision
import torchvision.transforms as transforms
import numpy as np
import pickle

# Plotting
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (12,8)

# Nice progress bars. Might be useful for this problem
from tqdm import tqdm, trange

from google.colab import drive
drive.mount('/content/drive')

def train(
    model: nn.Module, optimizer: Adam, train_loader: DataLoader, val_loader: DataLoader, epochs: int = 20
) -> dict:

    model = model.to(DEVICE)
    loss_fn = nn.CrossEntropyLoss()
    acc_val_all = []
    acc_train_all = []
    best_val = 0.
    best_train = 0.
    best_iter = 0
    no_improvement = 0

    for epoch in range(epochs):
        for (x_batch,y_batch) in tqdm(train_loader):
            y_batch = to_one_hot(y_batch)
            x_batch,y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)
            optimizer.zero_grad()
            loss = loss_fn(model(x_batch), y_batch)
            loss.backward()
            optimizer.step()
            
        acc_train = classification_accuracy(model, train_loader)
        acc_val = classification_accuracy(model, val_loader)

        acc_val_all.append(acc_val)
        acc_train_all.append(acc_train)

        if acc_val > best_val:
          best_val = acc_val
          best_train = acc_train
          best_iter = epoch
          best_model = model

          print('Train Accuracy: {}'.format(acc_train))
          print('Validation Accuracy: {}'.format(acc_val))

          no_improvement = 0

        else:
          no_improvement += 1

        # if no_improvement == 5:
        #   break

    return({'train_history': acc_train_all,
            'val_history': acc_val_all,
            'best_iter': best_iter,
            'best_val': best_val,
            'best_train': best_train,
            'model': best_model})

def classification_accuracy(model, data_loader):
  total_correct = 0.
  total = 0.
  for (x_batch,y_batch) in data_loader:
    if next(model.parameters()).is_cuda:
      x_batch,y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)
    with torch.no_grad():
      preds = torch.argmax(model(x_batch), 1)
      correct = torch.sum(preds == y_batch).item()
      total_correct += correct
      total += len(y_batch)
  return(total_correct / total)

def to_one_hot(a: np.ndarray) -> np.ndarray:
    """Helper function. Converts data from categorical to one-hot encoded.

    Args:
        a (np.ndarray): Input array of integers with shape (n,).

    Returns:
        np.ndarray: Array with shape (n, c), where c is maximal element of a.
            Each element of a, has a corresponding one-hot encoded vector of length c.
    """
    r = np.zeros((len(a), 10))
    r[np.arange(len(a)), a] = 1
    return torch.from_numpy(r)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(DEVICE)  # this should print out CUDA
#DEVICE = 'cpu'

class net_1(nn.Module):
    def __init__(self,dim_in,dim_out):
        super().__init__()
        self.a1 = nn.Linear(dim_in, dim_out)
        self.dim_in = dim_in
        self.dim_out = dim_out
    def forward(self,x):
        output = self.a1(x.view(-1,self.dim_in))
        return output.view(-1,self.dim_out)

class net_2(nn.Module):
    def __init__(self,dim_in,dim_out,M):
        super().__init__()
        self.a1 = nn.Linear(dim_in, M)
        self.a2 = nn.ReLU()
        self.a3 = nn.Linear(M,dim_out)
        self.dim_in = dim_in
        self.dim_out = dim_out
    def forward(self,x):
        output = self.a1(x.view(-1,self.dim_in))
        output = self.a2(output)
        output = self.a3(output)
        return output.view(-1,self.dim_out)

class net_3(nn.Module):
    def __init__(self,num_filters,filter_size,pool_size,dim_in,dim_out):
        super().__init__()
        dim_val = int((((33-filter_size)/pool_size) ** 2) * num_filters)
        self.dim_val = dim_val
        self.dim_in = dim_in
        self.dim_out = dim_out
        self.a1 = nn.Conv2d(
            in_channels=3,
            out_channels=num_filters,
            kernel_size = filter_size, 
            stride = 1
        )
        self.a2 = nn.ReLU()
        self.a3 = nn.MaxPool2d(
            kernel_size=pool_size,
            stride=pool_size
        )
        self.a4 = nn.Linear(dim_val,dim_out)
    def forward(self,x):
        output = self.a1(x)
        output = self.a2(output)
        output = self.a3(output).view(-1,1,self.dim_val)
        output = self.a4(output)
        return output.view(-1,self.dim_out)

def get_dataloaders():
  transform = transforms.ToTensor()
  train_dataset = torchvision.datasets.CIFAR10(
      "./data", 
      train=True, 
      download=True,
      transform=transform
  )
  test_dataset = torchvision.datasets.CIFAR10(
      "./data", 
      train=False, 
      download=True,
      transform=transform
  )

  total_obs = len(train_dataset)
  train_data, val_data = torch.utils.data.random_split(train_dataset, lengths = [int(total_obs * .8), int(total_obs * .2)]) 

  train_dl = DataLoader(train_data, batch_size=32, shuffle=True)
  val_dl = DataLoader(val_data, batch_size=32, shuffle=True)
  test_dl = DataLoader(test_dataset, batch_size=32, shuffle=True)

  return((train_dl, val_dl, test_dl))

def net_1_search(lr_vals, train_dl, val_dl):
  dim_in = 32 * 32 * 3
  dim_out = 10
  search_dict = {x: [] for x in ['lr', 'results']}

  for lr in lr_vals:
    print('----------------------------------------------')
    print('lr: {}'.format(lr))
    
    model = net_1(dim_in,dim_out)
    results = train(model, Adam(model.parameters(), lr = lr), train_loader = train_dl, val_loader = val_dl)

    search_dict['lr'].append(lr)
    search_dict['results'].append(results)

  return(search_dict)

def net_2_search(M_vals, lr_vals, train_dl, val_dl):
  dim_in = 32 * 32 * 3
  dim_out = 10
  search_dict = {x: [] for x in ['M', 'lr', 'results']}
  completed = False

  for lr in lr_vals:
    if completed == False:
      for M in M_vals:
        if completed == False:
          print('----------------------------------------------')
          print('M: {}, lr: {}'.format(M,lr))
          
          model = net_2(dim_in,dim_out,M)
          results = train(model, Adam(model.parameters(), lr = lr), train_loader = train_dl, val_loader = val_dl)

          search_dict['M'].append(M)
          search_dict['lr'].append(lr)
          search_dict['results'].append(results)

          if results['best_val'] > .5:
            completed = True
            break
        else:
          break
    else:
      break

  return(search_dict)

def net_3_search(architectures, num_filters, lr_vals, train_dl, val_dl):
  dim_in = 32 * 32 * 3
  dim_out = 10
  search_dict = {x: [] for x in ['architecture', 'num_filters', 'lr', 'results']}
  completed = False

  for lr in lr_vals:
    if completed == False:
      for num_filter in num_filters:
        if completed == False:
          for architecture in architectures:
            print('----------------------------------------------')
            print('architecture: {}, num_filters: {}, lr: {}'.format(architecture,num_filter,lr))

            filter_size,pool_size = architecture
            
            model = net_3(num_filter, filter_size, pool_size, dim_in, dim_out)
            results = train(model, Adam(model.parameters(), lr = lr), train_loader = train_dl, val_loader = val_dl)

            search_dict['architecture'].append(architecture)
            search_dict['num_filters'].append(num_filter)
            search_dict['lr'].append(lr)
            search_dict['results'].append(results)

            if results['best_val'] > .65:
              completed = True
              break
          else:
            break
      else:
        break
    else:
      break

  return(search_dict)

def get_best_model_accuracy(results_dict,test_dl):
  best_model_val = max([x['best_val'] for x in results_dict['results']])
  best_model_id = [x['best_val'] for x in results_dict['results']].index(best_model_val)
  return(classification_accuracy(results_dict['results'][best_model_id]['model'],test_dl))

def plot_model(results_dict,i,letter):
  best_val_array = -1 * np.array([x['best_val'] for x in results_dict['results']])
  best_val_indices = np.argsort(best_val_array)

  dict_names = results_dict.keys()
  dict_names = [x for x in dict_names if x != 'results']

  colors = ['b', 'g', 'r', 'c', 'm']

  for j, idx in enumerate(best_val_indices[:5]):
    s = ''
    for key_name in dict_names:
      s += key_name + ': {}, '.format(results_dict[key_name][idx])

    plt.plot(
        results_dict['results'][idx]['train_history'], 
        '{}o--'.format(colors[j]), 
        label = '{}Train'.format(s)
    )
    plt.plot(
        results_dict['results'][idx]['val_history'], 
        '{}o-'.format(colors[j]), 
        label = '{}Val'.format(s)
    )

  plt.title('Model {}: Training and Validation'.format(i+1))
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.savefig('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/B1{}.png'.format(letter), dpi=200)
  plt.close()

train_tf = False

def main():

  # get the data

  train_dl, val_dl, test_dl = get_dataloaders()

  if train_tf == True:

    # first network
    lr_vals = [1e-3,5e-3,1e-4,5e-4,1e-5]
    net_1_search_dict = net_1_search(lr_vals,train_dl,val_dl)
    with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_1_search_dict.pickle', 'wb') as handle:
        pickle.dump(net_1_search_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)

    # second network
    M_vals = [600,700,800]
    lr_vals = [1e-3,5e-3,1e-4,5e-4,1e-5]
    net_2_search_dict = net_2_search(M_vals,lr_vals,train_dl,val_dl)
    with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_2_search_dict.pickle', 'wb') as handle:
        pickle.dump(net_2_search_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)

    # third network
    architectures = [(5,14), (6,9), (9,6)]
    num_filters = [100,150,200]
    lr_vals = [1e-3,5e-3,1e-4,5e-4,1e-5]
    net_3_search_dict = net_3_search(architectures,num_filters,lr_vals,train_dl,val_dl)
    with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_3_search_dict.pickle', 'wb') as handle:
        pickle.dump(net_3_search_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)

  # import the results

  with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_1_search_dict.pickle', 'rb') as handle:
    net_1_search_dict = pickle.load(handle)

  with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_2_search_dict.pickle', 'rb') as handle:
    net_2_search_dict = pickle.load(handle)

  with open('/content/drive/MyDrive/Grad School/2021-2022/Autumn/CSE 546/Assignments/HW4/net_3_search_dict.pickle', 'rb') as handle:
    net_3_search_dict = pickle.load(handle)

  letters = ['a', 'b', 'c']
  
  # plot the problem
  for i, results_dict in enumerate([net_1_search_dict, net_2_search_dict, net_3_search_dict]):
    print('Network {} Test Accuracy: {}'.format(i+1, get_best_model_accuracy(results_dict, test_dl)))
    plot_model(results_dict,i,letters[i])

main()